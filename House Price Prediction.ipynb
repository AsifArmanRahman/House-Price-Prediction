{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6615a88",
   "metadata": {},
   "source": [
    "## Asif Arman Rahman\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34820b18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CategoricalImputer' from 'sklearn_pandas' (C:\\Users\\Asif\\miniconda3\\envs\\main\\lib\\site-packages\\sklearn_pandas\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleImputer\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn_pandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CategoricalImputer\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OneHotEncoder\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_score\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'CategoricalImputer' from 'sklearn_pandas' (C:\\Users\\Asif\\miniconda3\\envs\\main\\lib\\site-packages\\sklearn_pandas\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df =  pd.read_csv('data/test.csv')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Size of train data : {}\" .format(train_df.shape))\n",
    "\n",
    "print (\"Size of test data : {}\" .format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 'Id' column\n",
    "train_ID = train_df['Id']\n",
    "test_ID = test_df['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train_df.drop(\"Id\", axis = 1, inplace = True)\n",
    "test_df.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447d14f",
   "metadata": {},
   "source": [
    "## Q1 (A)\n",
    "\n",
    "### Missing data and Categorical data Handle\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the numeric columns\n",
    "train = train_df.select_dtypes(['int64', 'float64'])\n",
    "test = test_df.select_dtypes(['int64', 'float64'])\n",
    "\n",
    "# Dropping the insignificant features\n",
    "train = train.drop(['GarageYrBlt', 'TotRmsAbvGrd', '1stFlrSF', 'GarageCars'], axis=1)\n",
    "test = test.drop(['GarageYrBlt', 'TotRmsAbvGrd', '1stFlrSF', 'GarageCars'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d041bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na = (train.isnull().sum() / len(train)) * 100\n",
    "train_na = train_na.drop(train_na[train_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :train_na})\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(4, 4))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=train_na.index, y=train_na)\n",
    "plt.xlabel('Features', fontsize=8)\n",
    "plt.ylabel('Percent of missing values', fontsize=8)\n",
    "plt.title('Percent missing data by feature', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_na = (test.isnull().sum() / len(test)) * 100\n",
    "test_na = test_na.drop(test_na[test_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :test_na})\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(4, 4))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=test_na.index, y=test_na)\n",
    "plt.xlabel('Features', fontsize=8)\n",
    "plt.ylabel('Percent of missing values', fontsize=8)\n",
    "plt.title('Percent missing data by feature', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a357d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique value count in each feature\n",
    "cat_count = train.apply(lambda x: x.value_counts().shape[0]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns in numerical columns\n",
    "cats_in_nums = cat_count.loc[cat_count < 50].index\n",
    "\n",
    "# Converting the type of filtered numerical columns to categorical\n",
    "train.loc[:, cats_in_nums] = train.loc[:, cats_in_nums].astype('object')\n",
    "test.loc[:, cats_in_nums] = test.loc[:, cats_in_nums].astype('object')\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5230cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Neighborhood feature to the filtered datasets\n",
    "train['Neighborhood'] = train_df['Neighborhood']\n",
    "test['Neighborhood'] = test_df['Neighborhood']\n",
    "\n",
    "corrTrain = train\n",
    "\n",
    "# Extracting the SalePrice from training data\n",
    "y_train = np.log(train['SalePrice'].values)\n",
    "train = train.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing numerical values with the median value as the features are not uniformly distributed\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_num = imputer.fit_transform(train.select_dtypes(['int64', 'float64']))\n",
    "test_num = imputer.transform(test.select_dtypes(['int64', 'float64']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing categorical value with the most frequent value\n",
    "\n",
    "cat_columns = train.select_dtypes(['object']).columns\n",
    "cat_imputer = CategoricalImputer()\n",
    "train_cat = cat_imputer.fit_transform(train.loc[:, cat_columns].values)\n",
    "test_cat = cat_imputer.transform(test.loc[:, cat_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9670c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the categorical columns\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "combined_cat_data = np.vstack([train_cat, test_cat])\n",
    "combined_cat = one_hot_encoder.fit_transform(combined_cat_data).todense()\n",
    "\n",
    "train_cat = combined_cat[:train.shape[0]]\n",
    "test_cat = combined_cat[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598f858",
   "metadata": {},
   "source": [
    "***\n",
    "## Q1 (B)\n",
    "\n",
    "### Correlation matrix (in terms of target variable/feature)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c20139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=70)\n",
    "sns.heatmap(corrTrain.corr(), cmap='Spectral', linewidths=1.5, square=True, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a916e92",
   "metadata": {},
   "source": [
    "***\n",
    "## Q1 (C)\n",
    "\n",
    "### Feature Scaling the numeric columns\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Creating a scaler for input features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Transforming the input features of both train and test\n",
    "train_num = scaler.fit_transform(train_num)\n",
    "test_num = scaler.transform(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc322e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((train_num, train_cat))\n",
    "X_test = np.hstack((test_num, test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7d281",
   "metadata": {},
   "source": [
    "***\n",
    "## Q2 (A)\n",
    "\n",
    "### Use Support Vector Machine to predict Housing Price\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(model):\n",
    "    error = np.sqrt(abs(cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')))\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "svr = SVR(kernel='linear')\n",
    "print(rmse(svr).mean(), rmse(svr).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad1bad",
   "metadata": {},
   "source": [
    "***\n",
    "## Q2 (B)\n",
    "\n",
    "### Decision Tree with maximum depth restriction\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a33563",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "\n",
    "print(rmse(tree_reg).mean(), rmse(tree_reg).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd457c6a",
   "metadata": {},
   "source": [
    "### Decision Tree with no maximum depth restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(random_state=42, max_depth=None)\n",
    "\n",
    "print(rmse(tree_reg).mean(), rmse(tree_reg).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bae572",
   "metadata": {},
   "source": [
    "***\n",
    "## Q2 (C)\n",
    "\n",
    "### Random Forest with various n_estimators count\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f10ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "array =  [10, 100, 1000]\n",
    "\n",
    "for i in array:\n",
    "    forest_reg = RandomForestRegressor(n_estimators=i)\n",
    "    \n",
    "    print('For n_estimator: ', i, ' ', rmse(tree_reg).mean(), rmse(tree_reg).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0928ad",
   "metadata": {},
   "source": [
    "***\n",
    "## Q3\n",
    "\n",
    "### Perform PCA and then apply random forest algorithm\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=120)\n",
    "pca.fit(X_train)\n",
    "\n",
    "x_pca = pca.transform(X_train)\n",
    "x_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda164d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "error = np.sqrt(abs(cross_val_score(forest_reg, x_pca, y_train, cv=5, scoring='neg_mean_squared_error')))\n",
    "\n",
    "print(error.mean(),error.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56ae83",
   "metadata": {},
   "source": [
    "As it can be seen that applying PCA does improve RandomForestRegressor score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07736ccc",
   "metadata": {},
   "source": [
    "***\n",
    "# Submission\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49591cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg.fit(x_pca,y_train)\n",
    "house = forest_reg.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5560a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = house\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43d48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}